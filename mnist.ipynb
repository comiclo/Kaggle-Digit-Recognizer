{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = train.take(np.random.permutation(len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_size = 40000\n",
    "\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(data, labels=None):\n",
    "    data = data.reshape((-1,28,28,1)).astype(np.float32)\n",
    "    try:\n",
    "        labels = labels.astype(np.float32)\n",
    "        labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)\n",
    "        return data, labels\n",
    "    except:\n",
    "        return data\n",
    "    \n",
    "    \n",
    "train_data = train.iloc[:train_size,1:].as_matrix()\n",
    "train_labels = train.iloc[:train_size,0].as_matrix()\n",
    "\n",
    "valid_data = train.iloc[train_size:,1:].as_matrix()\n",
    "valid_labels = train.iloc[train_size:,0].as_matrix()\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "valid_data, valid_labels = reformat(valid_data, valid_labels)\n",
    "\n",
    "#test_data = test.as_matrix()\n",
    "#test_data = reformat(test_data)\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2364366d6d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEYJJREFUeJzt3XvMXHWdx/H3R7AFWy7twjZNLdZy2V1AWmJDNgSlG+Qi\nf1CkgQgNwWioinUV1rgNSoTdyIKrNss/ag0F3AhIuEhDEIVCuYSVUIggUKxIytoLrSyXtly2XL77\nx5xnMzw885vpOWfmzMPv80omz8z5zvzmy2E+PWfOmZmfIgIzy88Hmm7AzJrh8JtlyuE3y5TDb5Yp\nh98sUw6/WaYcfrNMDW34JYWkVyV9t+lezAZN0tWSXpe0oV/PMbThL8yJiG91Kko6TtLTkl6TdI+k\nj5R9IklzJT1SjPWIpLkVxppV9PNa0d+nKow1VdItxT+Ez0k6q8JYEyWtkLRN0vOSLqgwliRdLul/\nisvlklRyrMMl/VrSC5Iqf+pM0lnFunpV0i8lTa0wViOvsYj4HPDpss/Vk4gYygsQwEGJ+n7AK8Dp\nwB7AvwO/LflcE4DngPOBicA/FrcnlBzvv4AfAnsCC4GXgf1LjnUd8AtgMnBM8d98WMmx/g24H5gC\n/B3wPHBSybG+CPwB+DAwA3gK+FLJsf4G+AKwoPWSrPS6OQzYDnyyWGfXAteXHKvR1xgwH9hQZX0k\ne+rXwJUb6x7+xcCDbbcnAa8Df1viuU4ANgJqW/bfZYIBHAL8L7BX27L7ygSj+G/aCRzStuxnwGUl\n1+km4IS22/9SIRgPAovbbn++bDDaxjiohvBfClzbdvvAYh3uVWKsRl9j/Q7/sO/2pxwGPDZyIyJe\nBZ4plpcZ6/Eo1njhsQpjPRsR22sY6xDgrYhYV3UsSVOA6bStswp9waj1X3GsOo1+XfyJ1j/Gh9Qw\n1rC8xmoxnsM/mdYuWbttwF7vs7G21TgWvLu3smONjDd6rMll3/fXaJj/X9Y1Vi3Gc/h3AHuPWrYP\nrfd7HmvssRg1XtmxRsYbPdaOUVu2Jgzz+q9rrFqM5/A/CcwZuSFpEq33d0+WHOuIUVutIyqMNVtS\n+7/oc0qOtQ7YXdLBVceKiJeAzbStswp9waj1X3GsOo1+XRxI62Dbuo6P6H2sYXmN1aNfBxOqXuh+\nwG9/WrtRC2kdif0e1Y/Efo16jvb/Fvh+0ddpVDvafz2tI/6TqH60/zLgXuo52v8lYC2tI/1Vj/ar\nWFeHFv/f9wAmlhzrMFq7058o1lmVo/2Nvsbw0f7kfT4FPE3rCOxqYFZb7ULgV7vwfEcCjxRjPQoc\n2VZbBDy5C2PNKvp5ndbpsE+11T5Ba/e417GmAr8EXqV1dPisttoBtHYnD+hxrInAiiIcW4ALRtV3\nAJ/ocSwVYXixuHyPdx/JfhJYtAvrK0Zd1rfVfwVcuAvr7KxiXb0K3ApMbav9GPjxLozV2Gus3+FX\n8SRDR9IbtI7SXhERFzXdj9kgSbqS1ucLtkbEQX15jmENv5n113g+4GdmFTj8ZpnafZBPVseXNsws\nLSJ6+qBVpS2/pJMk/UHSM5KWVhnLzAar9AE/SbvR+uDE8cAG4GHgzIh4KvEYb/nN+mwQW/6jgGci\n4tmI2EnrwygLKoxnZgNUJfwzgD+33d5QLHsXSYslrZG0psJzmVnN+n7ALyKWA8vBu/1mw6TKln8j\nMLPt9oeLZWY2DlQJ/8PAwZI+KmkC8FlgZT1tmVm/ld7tj4i3JC0Bfg3sBqyIiGH4SqeZ9WCgn+33\ne36z/hvIh3zMbPxy+M0y5fCbZcrhN8uUw2+WKYffLFMD/T6/Dd6SJUuS9SuuuCJZnz17drK+fv36\nXW3JhoS3/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxT/lbf+8BBB3Wezemuu+5KPnbmzJnJ+t13352s\nH3/88cm6DZ6/1WdmSQ6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5S/0vs+cMkll3SsdTuP3023zwnY\n+OUtv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKZ/nHwf22GOPZH3//fcvPfbOnTuT9bVr15Ye\n24ZbpfBLWg9sB94G3oqIeXU0ZWb9V8eW/x8i4oUaxjGzAfJ7frNMVQ1/AHdJekTS4rHuIGmxpDWS\n1lR8LjOrUdXd/mMiYqOkvwbulPR0RNzXfoeIWA4sB/+Ap9kwqbTlj4iNxd+twC3AUXU0ZWb9Vzr8\nkiZJ2mvkOnAC8ERdjZlZf1XZ7Z8G3CJpZJxrI+KOWrqyd/nyl7+crB933HGlxz7//POT9ZUrV5Ye\n24Zb6fBHxLPAnBp7MbMB8qk+s0w5/GaZcvjNMuXwm2XK4TfLlKfoHgILFy5M1q+66qpkfdKkSR1r\nt99+e/KxixYtSta3bduWrNvw8RTdZpbk8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNM+Tz/AOy7777J\n+urVq5P1j33sY8n6K6+80rE2Y8aM5GNff/31ZN3GH5/nN7Mkh98sUw6/WaYcfrNMOfxmmXL4zTLl\n8JtlylN012Dq1KnJ+h13pH/RvMp5fIBTTjmlY83n8a0Tb/nNMuXwm2XK4TfLlMNvlimH3yxTDr9Z\nphx+s0z5PH8NTjvttGT94x//eKXxzz333GT9gQceqDS+5anrll/SCklbJT3RtmyqpDsl/bH4O6W/\nbZpZ3XrZ7b8aOGnUsqXAqog4GFhV3DazcaRr+CPiPuDFUYsXANcU168BTq25LzPrs7Lv+adFxObi\n+vPAtE53lLQYWFzyecysTyof8IuISP0wZ0QsB5ZDvj/gaTaMyp7q2yJpOkDxd2t9LZnZIJQN/0rg\nnOL6OcCt9bRjZoPSdbdf0nXAfGA/SRuA7wCXATdI+gLwHHBGP5scdnPmzOnr+Bs2bOjr+JanruGP\niDM7lI6ruRczGyB/vNcsUw6/WaYcfrNMOfxmmXL4zTLlr/TWoNsU3FJPMyZnZ++9907WL7roomR9\n5syZyXpq+vlvfOMbycdu3LgxWX8/8JbfLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUz/PXoNtX\nelPnmwHWrVtXqd6kPffcM1m/9NJLO9bmz5+ffOwRRxxRpqWeHH744cn6iSeemKxv2rSpznYa4S2/\nWaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Ypn+cfAi+99FKlepOuuuqqZP30008fUCe75tBDD03W\nu33f/4ILLqiznUZ4y2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrn+Xs0YcKEjrXdd6+2Gl97\n7bVKj69i4sSJyfrVV1+drJ9xRnp29tRvGbzxxhvJx95xxx3J+g033JCsL1u2rGNt2rRpyceed955\nyfqNN96YrD/44IPJ+jDouuWXtELSVklPtC27WNJGSb8rLif3t00zq1svu/1XAyeNsXxZRMwtLrfX\n25aZ9VvX8EfEfcCLA+jFzAaoygG/r0p6vHhbMKXTnSQtlrRG0poKz2VmNSsb/h8Bs4G5wGbgB53u\nGBHLI2JeRMwr+Vxm1gelwh8RWyLi7Yh4B/gpcFS9bZlZv5UKv6TpbTc/AzzR6b5mNpy6nqCWdB0w\nH9hP0gbgO8B8SXOBANYDX+xjj0NhypSOhzWYNGlSpbFffvnlZH3y5MnJ+o4dOzrWPvShDyUf+5Of\n/CRZ73Yev5tVq1Z1rH37299OPrbbnADdPoOQOpf/zjvvJB/brbfxcB6/m67hj4gzx1h8ZR96MbMB\n8sd7zTLl8JtlyuE3y5TDb5Yph98sU+o2fXStTyYN7skGqNtpoUsuuaTS+EcffXSy/tBDD3WsdZuK\n+rHHHivV04h77703WU99NXbRokXJxy5dujRZ/8AHym+7VqxYkayfe+65pcduWkSol/t5y2+WKYff\nLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrn+Wswb176R4p+85vfJOvdvrK7ffv2ZD31098333xz8rFL\nlixJ1rvp9rPjb775ZsfaPvvsU+m5u0l9huHEE09MPvYvf/lL3e0MjM/zm1mSw2+WKYffLFMOv1mm\nHH6zTDn8Zply+M0y5fP8Q+Dyyy9P1rtNF93t57n7qdt36rv9RHbK22+/nazfc889yfrZZ5/dsbZ1\n69ZSPY0HPs9vZkkOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8tU1/P8kmYCPwOm0ZqSe3lE/IekqcAv\ngFm0puk+IyJe6jKWz/OX0O33Ar75zW92rC1cuLDudt5FSp9STr2+Vq9enXzsbbfdlqwvW7YsWc9V\nnef53wL+KSIOBf4e+IqkQ4GlwKqIOBhYVdw2s3Gia/gjYnNEPFpc3w6sBWYAC4BrirtdA5zarybN\nrH679J5f0izgSOAhYFpEbC5Kz9N6W2Bm48Tuvd5R0mTgJuDrEbGt/b1eRESn9/OSFgOLqzZqZvXq\nacsv6YO0gv/ziBj5RcgtkqYX9enAmN+UiIjlETEvItJHrcxsoLqGX61N/JXA2oj4YVtpJXBOcf0c\n4Nb62zOzfunlVN8xwP3A74GR72deSOt9/w3AAcBztE71vdhlLJ/q64PU12oPOOCA5GMPPPDAZL3b\n9OOzZ89O1o899tiOtU2bNiUfu3PnzmTdxtbrqb6u7/kj4gGg02DH7UpTZjY8/Ak/s0w5/GaZcvjN\nMuXwm2XK4TfLlMNvlin/dLfZ+4x/utvMkhx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Z\nphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNv\nlqmu4Zc0U9I9kp6S9KSkrxXLL5a0UdLvisvJ/W/XzOrSddIOSdOB6RHxqKS9gEeAU4EzgB0R8f2e\nn8yTdpj1Xa+Tduzew0Cbgc3F9e2S1gIzqrVnZk3bpff8kmYBRwIPFYu+KulxSSskTenwmMWS1kha\nU6lTM6tVz3P1SZoM3At8NyJuljQNeAEI4F9pvTX4fJcxvNtv1me97vb3FH5JHwRuA34dET8coz4L\nuC0iDu8yjsNv1me1TdQpScCVwNr24BcHAkd8BnhiV5s0s+b0crT/GOB+4PfAO8XiC4Ezgbm0dvvX\nA18sDg6mxvKW36zPat3tr4vDb9Z/te32m9n7k8NvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK\n4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZ6voDnjV7AXiu7fZ+xbJhNKy9DWtf4N7KqrO3j/R6x4F+\nn/89Ty6tiYh5jTWQMKy9DWtf4N7Kaqo37/abZcrhN8tU0+Ff3vDzpwxrb8PaF7i3shrprdH3/GbW\nnKa3/GbWEIffLFONhF/SSZL+IOkZSUub6KETSesl/b6YdrzR+QWLORC3SnqibdlUSXdK+mPxd8w5\nEhvqbSimbU9MK9/ouhu26e4H/p5f0m7AOuB4YAPwMHBmRDw10EY6kLQemBcRjX8gRNIngR3Az0am\nQpP0PeDFiLis+IdzSkT885D0djG7OG17n3rrNK3852hw3dU53X0dmtjyHwU8ExHPRsRO4HpgQQN9\nDL2IuA94cdTiBcA1xfVraL14Bq5Db0MhIjZHxKPF9e3AyLTyja67RF+NaCL8M4A/t93eQIMrYAwB\n3CXpEUmLm25mDNPapkV7HpjWZDNj6Dpt+yCNmlZ+aNZdmenu6+YDfu91TETMBT4NfKXYvR1K0XrP\nNkznan8EzKY1h+Nm4AdNNlNMK38T8PWI2NZea3LdjdFXI+utifBvBGa23f5wsWwoRMTG4u9W4BZa\nb1OGyZaRGZKLv1sb7uf/RcSWiHg7It4BfkqD666YVv4m4OcRcXOxuPF1N1ZfTa23JsL/MHCwpI9K\nmgB8FljZQB/vIWlScSAGSZOAExi+qcdXAucU188Bbm2wl3cZlmnbO00rT8Prbuimu4+IgV+Ak2kd\n8f8T8K0meujQ12zgseLyZNO9AdfR2g18k9axkS8AfwWsAv4I3AVMHaLe/pPWVO6P0wra9IZ6O4bW\nLv3jwO+Ky8lNr7tEX42sN3+81yxTPuBnlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2Xq/wAQTYRe\nUKjcXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2364366d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 100\n",
    "\n",
    "train_data.shape\n",
    "plt.title(train_labels[index])\n",
    "plt.imshow(train_data[index].reshape((28,28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 0: 5684422.500000\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 12.2%\n",
      "Minibatch loss at step 500: 899133.375000\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 1000: 467014.875000\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 1500: 217927.125000\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 2000: 254951.968750\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 2500: 123595.062500\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 3000: 93186.625000\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 3500: 128774.484375\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 4000: 67391.078125\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 4500: 76454.367188\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 5000: 59299.140625\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 94.7%\n",
      "Minibatch loss at step 5500: 59948.562500\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 95.0%\n",
      "Minibatch loss at step 6000: 23923.871094\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 95.2%\n",
      "Minibatch loss at step 6500: 55488.218750\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 95.6%\n",
      "Minibatch loss at step 7000: 54474.171875\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 95.7%\n",
      "Minibatch loss at step 7500: 44716.410156\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 95.6%\n",
      "Minibatch loss at step 8000: 47728.792969\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 8500: 14640.648438\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 96.0%\n",
      "Minibatch loss at step 9000: 59318.304688\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 96.4%\n",
      "Minibatch loss at step 9500: 4516.221191\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 96.5%\n",
      "Minibatch loss at step 10000: 38745.769531\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 96.5%\n",
      "Minibatch loss at step 10500: 7605.832031\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 96.4%\n",
      "Minibatch loss at step 11000: 29131.197266\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 96.6%\n",
      "Minibatch loss at step 11500: 7833.912598\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 96.7%\n",
      "Minibatch loss at step 12000: 21228.773438\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 97.0%\n",
      "Minibatch loss at step 12500: 10987.826172\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 97.0%\n",
      "Minibatch loss at step 13000: 14201.218750\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 97.2%\n",
      "Minibatch loss at step 13500: 9935.580078\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 97.2%\n",
      "Minibatch loss at step 14000: 13552.900391\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 97.3%\n",
      "Minibatch loss at step 14500: 4730.732422\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 97.4%\n",
      "Minibatch loss at step 15000: 9563.031250\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 97.3%\n",
      "Minibatch loss at step 15500: 18291.443359\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 97.3%\n",
      "Minibatch loss at step 16000: 6384.661133\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 16500: 13867.238281\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 17000: 1953.706055\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 17500: 11873.446289\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 18000: 7599.806152\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 18500: 7149.533691\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 97.7%\n",
      "Minibatch loss at step 19000: 5663.101074\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 19500: 1907.456543\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 97.5%\n",
      "Minibatch loss at step 20000: 1384.286621\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 97.5%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "image_size = 28\n",
    "num_channels = 1\n",
    "keep_prob = 0.8\n",
    "filter_size = 5\n",
    "channel_depths1 = 32\n",
    "channel_depths2 = 64\n",
    "num_hidden = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_data = tf.placeholder(dtype=np.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(dtype=np.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_data = tf.constant(valid_data)\n",
    "    #tf_test_data = tf.constant(test_data)\n",
    "\n",
    "    w1 = tf.Variable(tf.truncated_normal(shape=[filter_size, filter_size, num_channels, channel_depths1]))\n",
    "    b1 = tf.Variable(tf.truncated_normal(shape=[channel_depths1]))\n",
    "    w2 = tf.Variable(tf.truncated_normal(shape=[filter_size, filter_size, channel_depths1, channel_depths2]))\n",
    "    b2 = tf.Variable(tf.truncated_normal(shape=[channel_depths2]))\n",
    "\n",
    "    w3 = tf.Variable(tf.truncated_normal(shape=[image_size*image_size//16 * channel_depths2, num_hidden]))\n",
    "    b3 = tf.Variable(tf.truncated_normal(shape=[num_hidden]))\n",
    "\n",
    "    w4 = tf.Variable(tf.truncated_normal(shape=[num_hidden, num_labels]))\n",
    "    b4 = tf.Variable(tf.truncated_normal(shape=[num_labels]))\n",
    "\n",
    "\n",
    "    def model(data, keep_prob=1.0):\n",
    "        # first conv layer\n",
    "        conv = tf.nn.conv2d(data, w1, strides=[1,1,1,1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + b1)\n",
    "        hidden = tf.nn.avg_pool(hidden, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "        # second conv layer\n",
    "        conv = tf.nn.conv2d(hidden, w2, strides=[1,1,1,1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + b2)\n",
    "        hidden = tf.nn.avg_pool(hidden, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "        # flat the tensor\n",
    "        shape = hidden.get_shape().as_list()\n",
    "        hidden = tf.reshape(hidden, shape=[shape[0], -1])\n",
    "\n",
    "        hidden = tf.nn.relu(tf.matmul(hidden, w3) + b3)\n",
    "        hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "        return tf.matmul(hidden, w4) + b4\n",
    "\n",
    "    logits = model(tf_train_data, keep_prob)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimization\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = 1e-4\n",
    "    decay_steps = 1e+3\n",
    "    decay_rate = 0.975\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate=learning_rate, \n",
    "                                               global_step=global_step,\n",
    "                                               decay_steps=decay_steps,\n",
    "                                               decay_rate=decay_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(model(tf_valid_data))\n",
    "    #test_prediction = tf.nn.softmax(model(tf_test_data))\n",
    "\n",
    "num_steps = 20000+1\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step + 1) * batch_size % train_labels.shape[0]\n",
    "        batch_train_data = train_data[offset - batch_size:offset, :, :, :]\n",
    "        batch_train_labels = train_labels[offset - batch_size:offset]\n",
    "\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_train_data = train_data[offset:(offset + batch_size), :, :, :]\n",
    "        batch_train_labels = train_labels[offset:(offset + batch_size), :]\n",
    "\n",
    "        feed_dict = {tf_train_data:batch_train_data, tf_train_labels: batch_train_labels}\n",
    "        _, l, predictions =sess.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_train_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
